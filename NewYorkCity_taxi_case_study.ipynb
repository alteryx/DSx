{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.featuretools.com/\"><img src=\"img/featuretools-logo.png\" width=\"400\" height=\"200\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> New York City Taxi Ride Duration Prediction </h2>\n",
    "\n",
    "In this case study, we will build a predictive model to predict taxi ride ``duration``. We will do the following steps:\n",
    "* First install the dependencies\n",
    "* Next load the data \n",
    "* Define the outcome variable- the variable we are trying to predict. \n",
    "* Build features using featuretools package - that implements Deep Feature Synthesis. We will start with simple features and incrementally improve the feature definitions and examine the accuracy of the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Install Dependencies</h2>\n",
    "<p>If you have not done so already, download this repository <a href=\"https://github.com/Featuretools/DSx/archive/master.zip\">from git</a>. Once you have downloaded this archive, unzip it and cd into the directory from the command line. Next run the command ``./osx.sh`` if you are on a mac or ``./linux.sh`` if you are on linux. This should install all of the dependencies.</p>\n",
    "<p> If you are on a windows machine, open the requirements.txt folder and make sure to install each of the dependencies listed (featuretools, jupyter, pandas, sklearn, xgboost, numpy) </p>\n",
    "<p> Once you have installed all of the dependencies, open this notebook. On Mac and Linux, navigate to the directory that you downloaded from git and run ``jupyter notebook`` to be taken to this notebook in your default web browser. When you open the NewYorkCity_taxi_case_study.ipynb file in the web browser, you can step through the code by clicking the ``Run`` button at the top of the page. If you have any questions for how to use Jupyter, refer to google or the discussion forum.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Running the Code</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import featuretools as ft\n",
    "import utils\n",
    "from utils import load_nyc_taxi_data, compute_features\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from featuretools.primitives import (Day, Hour, Minute, Month, Weekday, Week, Weekend, Sum, Mean, Median, Std)\n",
    "ft.__version__\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the raw data  </h2>\n",
    "<p>If you have not yet downloaded the data it can be downloaded <a href=\"https://s3.amazonaws.com/mit-dsx-data/nyc-taxi-data.zip\">from S3</a>. Once you have downloaded the archive, unzip it and place trips.csv, passenger_cnt.csv, and vendors.csv in the nyc-taxi-data folder. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:19</td>\n",
       "      <td>2016-01-01 00:06:31</td>\n",
       "      <td>3</td>\n",
       "      <td>1.32</td>\n",
       "      <td>-73.961258</td>\n",
       "      <td>40.796200</td>\n",
       "      <td>False</td>\n",
       "      <td>-73.950050</td>\n",
       "      <td>40.787312</td>\n",
       "      <td>2</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:01:45</td>\n",
       "      <td>2016-01-01 00:27:38</td>\n",
       "      <td>1</td>\n",
       "      <td>13.70</td>\n",
       "      <td>-73.956169</td>\n",
       "      <td>40.707756</td>\n",
       "      <td>False</td>\n",
       "      <td>-73.939949</td>\n",
       "      <td>40.839558</td>\n",
       "      <td>1</td>\n",
       "      <td>1553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:01:47</td>\n",
       "      <td>2016-01-01 00:21:51</td>\n",
       "      <td>2</td>\n",
       "      <td>5.30</td>\n",
       "      <td>-73.993103</td>\n",
       "      <td>40.752632</td>\n",
       "      <td>False</td>\n",
       "      <td>-73.953903</td>\n",
       "      <td>40.816540</td>\n",
       "      <td>2</td>\n",
       "      <td>1204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:01:48</td>\n",
       "      <td>2016-01-01 00:16:06</td>\n",
       "      <td>1</td>\n",
       "      <td>7.19</td>\n",
       "      <td>-73.983009</td>\n",
       "      <td>40.731419</td>\n",
       "      <td>False</td>\n",
       "      <td>-73.930969</td>\n",
       "      <td>40.808460</td>\n",
       "      <td>2</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:02:49</td>\n",
       "      <td>2016-01-01 00:20:45</td>\n",
       "      <td>2</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-74.004631</td>\n",
       "      <td>40.747234</td>\n",
       "      <td>False</td>\n",
       "      <td>-73.976395</td>\n",
       "      <td>40.777237</td>\n",
       "      <td>1</td>\n",
       "      <td>1076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:03:21</td>\n",
       "      <td>2016-01-01 00:12:18</td>\n",
       "      <td>1</td>\n",
       "      <td>2.76</td>\n",
       "      <td>-73.956947</td>\n",
       "      <td>40.766380</td>\n",
       "      <td>False</td>\n",
       "      <td>-73.943008</td>\n",
       "      <td>40.796822</td>\n",
       "      <td>1</td>\n",
       "      <td>537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:04:20</td>\n",
       "      <td>2016-01-01 00:13:16</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-73.989120</td>\n",
       "      <td>40.738045</td>\n",
       "      <td>False</td>\n",
       "      <td>-73.991638</td>\n",
       "      <td>40.748993</td>\n",
       "      <td>1</td>\n",
       "      <td>536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:05:06</td>\n",
       "      <td>2016-01-01 00:32:46</td>\n",
       "      <td>1</td>\n",
       "      <td>10.60</td>\n",
       "      <td>-73.972755</td>\n",
       "      <td>40.764198</td>\n",
       "      <td>False</td>\n",
       "      <td>-73.834953</td>\n",
       "      <td>40.692356</td>\n",
       "      <td>1</td>\n",
       "      <td>1660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:05:06</td>\n",
       "      <td>2016-01-01 00:12:27</td>\n",
       "      <td>3</td>\n",
       "      <td>2.32</td>\n",
       "      <td>-73.962997</td>\n",
       "      <td>40.765808</td>\n",
       "      <td>False</td>\n",
       "      <td>-73.967758</td>\n",
       "      <td>40.790390</td>\n",
       "      <td>2</td>\n",
       "      <td>441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:05:15</td>\n",
       "      <td>2016-01-01 00:08:27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-73.973824</td>\n",
       "      <td>40.792049</td>\n",
       "      <td>False</td>\n",
       "      <td>-73.977913</td>\n",
       "      <td>40.783760</td>\n",
       "      <td>2</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id vendor_id     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
       "0   0         2 2016-01-01 00:00:19 2016-01-01 00:06:31                3   \n",
       "1   1         2 2016-01-01 00:01:45 2016-01-01 00:27:38                1   \n",
       "2   2         1 2016-01-01 00:01:47 2016-01-01 00:21:51                2   \n",
       "3   3         2 2016-01-01 00:01:48 2016-01-01 00:16:06                1   \n",
       "4   4         1 2016-01-01 00:02:49 2016-01-01 00:20:45                2   \n",
       "5   5         2 2016-01-01 00:03:21 2016-01-01 00:12:18                1   \n",
       "6   6         1 2016-01-01 00:04:20 2016-01-01 00:13:16                4   \n",
       "7   7         1 2016-01-01 00:05:06 2016-01-01 00:32:46                1   \n",
       "8   8         2 2016-01-01 00:05:06 2016-01-01 00:12:27                3   \n",
       "9   9         2 2016-01-01 00:05:15 2016-01-01 00:08:27                1   \n",
       "\n",
       "   trip_distance  pickup_longitude  pickup_latitude  store_and_fwd_flag  \\\n",
       "0           1.32        -73.961258        40.796200               False   \n",
       "1          13.70        -73.956169        40.707756               False   \n",
       "2           5.30        -73.993103        40.752632               False   \n",
       "3           7.19        -73.983009        40.731419               False   \n",
       "4           2.90        -74.004631        40.747234               False   \n",
       "5           2.76        -73.956947        40.766380               False   \n",
       "6           1.00        -73.989120        40.738045               False   \n",
       "7          10.60        -73.972755        40.764198               False   \n",
       "8           2.32        -73.962997        40.765808               False   \n",
       "9           0.73        -73.973824        40.792049               False   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  payment_type  trip_duration  \n",
       "0         -73.950050         40.787312             2          372.0  \n",
       "1         -73.939949         40.839558             1         1553.0  \n",
       "2         -73.953903         40.816540             2         1204.0  \n",
       "3         -73.930969         40.808460             2          858.0  \n",
       "4         -73.976395         40.777237             1         1076.0  \n",
       "5         -73.943008         40.796822             1          537.0  \n",
       "6         -73.991638         40.748993             1          536.0  \n",
       "7         -73.834953         40.692356             1         1660.0  \n",
       "8         -73.967758         40.790390             2          441.0  \n",
       "9         -73.977913         40.783760             2          192.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips, passenger_cnt, vendors = load_nyc_taxi_data()\n",
    "trips.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the Data \n",
    "Lets create entities and relationships. The three entities in this data are \n",
    "* trips \n",
    "* vendors (these are the cab)\n",
    "* passenger_cnt (a simple entity that has the unique number of passenger counts 1-8)\n",
    "\n",
    "This data has the following relationships\n",
    "* Vendors --> trips (the same vendor can have multiple trips - vendors is the ``parent_entity`` and trips it the child entity\n",
    "* passenger_cnt --> trips (the same passenger_cnt can appear in multiple trips. passenger_cnt is the ``parent_entity`` and trips is the child entity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = {\n",
    "        \"trips\": (trips, \"id\", 'pickup_datetime' ),\n",
    "        \"vendors\": (vendors, \"vendor_id\"),\n",
    "        \"passenger_cnt\": (passenger_cnt,\"passenger_count\")\n",
    "        }\n",
    "\n",
    "relationships = [(\"vendors\", \"vendor_id\",\"trips\", \"vendor_id\"), \n",
    "                (\"passenger_cnt\", \"passenger_count\",\"trips\", \"passenger_count\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can specify the time for each instance of the target_entity to calculate features. The timestamp represents the last time data can be used for calculating features by DFS. This is specified using a dataframe of cutoff times. Below we can see that the cutoff time for each trip is the pickup time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     pickup_datetime\n",
      "0   0 2016-01-01 00:00:19\n",
      "1   1 2016-01-01 00:01:45\n",
      "2   2 2016-01-01 00:01:47\n",
      "3   3 2016-01-01 00:01:48\n",
      "4   4 2016-01-01 00:02:49\n",
      "5   5 2016-01-01 00:03:21\n",
      "6   6 2016-01-01 00:04:20\n",
      "7   7 2016-01-01 00:05:06\n",
      "8   8 2016-01-01 00:05:06\n",
      "9   9 2016-01-01 00:05:15\n"
     ]
    }
   ],
   "source": [
    "cutoff_time = (trips[['id', 'pickup_datetime']])\n",
    "print cutoff_time.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 3: Create baseline features using DFS </h2>\n",
    "<p>Instead of manually creating features, such as month of <b>pickup_datetime</b>, we can let featuretools come up with them. </p>\n",
    "\n",
    "<p>Within featuretools there is a standard format for representing data that is used to set up predictions and build features.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As a note: Featuretools will try to interpret the types of variables. We can override this interpretation by specifying the types. In this case, I wanted <b>passenger_count</b> to be a type of Ordinal, and <b>vendor_id</b> to be of type Categorical. This was override occured while loading in the csv files.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create transform features using transform primitives\n",
    "\n",
    "As we described in the video, features fall into two major categories, ``transform`` and ``aggregate``. In Deep feature synthesis algorithm, we can create transform features by specifying ``transform`` primitives. Below we specify a ``transform`` primitive called ``weekend`` and here is what it does:\n",
    "\n",
    "* It can be applied to any ``datetime`` column in the data. \n",
    "* For each entry in the column, it assess if it is a ``weekend`` and returns a boolean. \n",
    "\n",
    "In this specific data, there are two ``datetime`` columns ``pickup_datetime`` and ``dropoff_datetime``. The tool automatically creates features using the primitive and these two columns as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "trans_primitives = [Weekend]\n",
    "\n",
    "features = ft.dfs(entities=entities,\n",
    "                   relationships=relationships,\n",
    "                   target_entity=\"trips\",\n",
    "                   trans_primitives=trans_primitives,\n",
    "                   agg_primitives=[],\n",
    "                   features_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here are the features created.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Feature: vendor_id>,\n",
       " <Feature: passenger_count>,\n",
       " <Feature: payment_type>,\n",
       " <Feature: dropoff_longitude>,\n",
       " <Feature: pickup_latitude>,\n",
       " <Feature: trip_duration>,\n",
       " <Feature: store_and_fwd_flag>,\n",
       " <Feature: trip_distance>,\n",
       " <Feature: dropoff_latitude>,\n",
       " <Feature: pickup_longitude>,\n",
       " <Feature: IS_WEEKEND(dropoff_datetime)>,\n",
       " <Feature: IS_WEEKEND(pickup_datetime)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix = compute_features(features,cutoff_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 4: Build the Model </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a model,\n",
    "* we first seperate the data into a porition of ``training`` (75% in this case) and a portion for ``testing`` \n",
    "* We also get the log of the trip duration so that a more linear relationship can be found.\n",
    "* We use ``XGBOOST`` to train a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separates the whole feature matrix into train data feature matrix, train data labels, and test data feature matrix \n",
    "X_train, y_train, X_test, y_test = utils.get_train_test_fm(feature_matrix,.75)\n",
    "y_train = np.log(y_train.values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.98698\tvalid-rmse:4.98587\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.973206\tvalid-rmse:0.972554\n",
      "[20]\ttrain-rmse:0.436417\tvalid-rmse:0.436489\n",
      "[30]\ttrain-rmse:0.380745\tvalid-rmse:0.382061\n",
      "[40]\ttrain-rmse:0.37503\tvalid-rmse:0.377282\n",
      "[50]\ttrain-rmse:0.367368\tvalid-rmse:0.370566\n",
      "[60]\ttrain-rmse:0.362789\tvalid-rmse:0.366918\n",
      "[70]\ttrain-rmse:0.358907\tvalid-rmse:0.364013\n",
      "[80]\ttrain-rmse:0.357262\tvalid-rmse:0.362921\n",
      "[90]\ttrain-rmse:0.354699\tvalid-rmse:0.361165\n",
      "[100]\ttrain-rmse:0.353081\tvalid-rmse:0.360219\n",
      "[110]\ttrain-rmse:0.351461\tvalid-rmse:0.359141\n",
      "[120]\ttrain-rmse:0.35009\tvalid-rmse:0.358254\n",
      "[130]\ttrain-rmse:0.34822\tvalid-rmse:0.357092\n",
      "[140]\ttrain-rmse:0.346831\tvalid-rmse:0.35624\n",
      "[150]\ttrain-rmse:0.346074\tvalid-rmse:0.355775\n",
      "[160]\ttrain-rmse:0.345375\tvalid-rmse:0.3554\n",
      "[170]\ttrain-rmse:0.34477\tvalid-rmse:0.355074\n",
      "[180]\ttrain-rmse:0.343869\tvalid-rmse:0.35461\n",
      "[190]\ttrain-rmse:0.343394\tvalid-rmse:0.354408\n",
      "[200]\ttrain-rmse:0.343124\tvalid-rmse:0.354356\n",
      "[210]\ttrain-rmse:0.342747\tvalid-rmse:0.354204\n",
      "[220]\ttrain-rmse:0.342269\tvalid-rmse:0.353976\n",
      "[226]\ttrain-rmse:0.34179\tvalid-rmse:0.353823\n",
      "Modeling RMSE 0.35382\n"
     ]
    }
   ],
   "source": [
    "model = utils.train_xgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 5: Adding more Transform Primitives</h2>\n",
    "\n",
    "* Adding ``Minute`` ``Hour`` ``Week`` ``Month`` ``Weekday`` primitives\n",
    "* All these transform primitives apply to ``datetime`` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_primitives = [Minute, Hour, Day, Week, Month, Weekday, Weekend]\n",
    "\n",
    "features = ft.dfs(entities=entities,\n",
    "                   relationships=relationships,\n",
    "                   target_entity=\"trips\",\n",
    "                   trans_primitives=trans_primitives,\n",
    "                   agg_primitives=[],\n",
    "                   drop_contains=['trips.test_data'],\n",
    "                   features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Feature: passenger_count>,\n",
       " <Feature: dropoff_longitude>,\n",
       " <Feature: payment_type>,\n",
       " <Feature: store_and_fwd_flag>,\n",
       " <Feature: vendor_id>,\n",
       " <Feature: pickup_latitude>,\n",
       " <Feature: pickup_longitude>,\n",
       " <Feature: trip_duration>,\n",
       " <Feature: trip_distance>,\n",
       " <Feature: dropoff_latitude>,\n",
       " <Feature: WEEKDAY(pickup_datetime)>,\n",
       " <Feature: WEEK(dropoff_datetime)>,\n",
       " <Feature: HOUR(pickup_datetime)>,\n",
       " <Feature: WEEKDAY(dropoff_datetime)>,\n",
       " <Feature: DAY(pickup_datetime)>,\n",
       " <Feature: MONTH(pickup_datetime)>,\n",
       " <Feature: WEEK(pickup_datetime)>,\n",
       " <Feature: DAY(dropoff_datetime)>,\n",
       " <Feature: MONTH(dropoff_datetime)>,\n",
       " <Feature: HOUR(dropoff_datetime)>,\n",
       " <Feature: IS_WEEKEND(pickup_datetime)>,\n",
       " <Feature: IS_WEEKEND(dropoff_datetime)>,\n",
       " <Feature: MINUTE(pickup_datetime)>,\n",
       " <Feature: MINUTE(dropoff_datetime)>,\n",
       " <Feature: passenger_cnt.WEEK(first_trips_time)>,\n",
       " <Feature: vendors.DAY(first_trips_time)>,\n",
       " <Feature: passenger_cnt.WEEKDAY(first_trips_time)>,\n",
       " <Feature: vendors.WEEKDAY(first_trips_time)>,\n",
       " <Feature: vendors.MONTH(first_trips_time)>,\n",
       " <Feature: passenger_cnt.DAY(first_trips_time)>,\n",
       " <Feature: passenger_cnt.MINUTE(first_trips_time)>,\n",
       " <Feature: passenger_cnt.HOUR(first_trips_time)>,\n",
       " <Feature: vendors.HOUR(first_trips_time)>,\n",
       " <Feature: passenger_cnt.MONTH(first_trips_time)>,\n",
       " <Feature: vendors.MINUTE(first_trips_time)>,\n",
       " <Feature: vendors.WEEK(first_trips_time)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix = compute_features(features,cutoff_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 5: Build the new model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separates the whole feature matrix into train data feature matrix, train data labels, and test data feature matrix \n",
    "X_train, y_train, X_test, y_test = utils.get_train_test_fm(feature_matrix,.75)\n",
    "y_train = np.log(y_train.values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.99672\tvalid-rmse:4.99546\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.926123\tvalid-rmse:0.925607\n",
      "[20]\ttrain-rmse:0.398269\tvalid-rmse:0.398866\n",
      "[30]\ttrain-rmse:0.336353\tvalid-rmse:0.338614\n",
      "[40]\ttrain-rmse:0.319268\tvalid-rmse:0.322974\n",
      "[50]\ttrain-rmse:0.29361\tvalid-rmse:0.299003\n",
      "[60]\ttrain-rmse:0.281483\tvalid-rmse:0.288059\n",
      "[70]\ttrain-rmse:0.257367\tvalid-rmse:0.265217\n",
      "[80]\ttrain-rmse:0.242748\tvalid-rmse:0.251557\n",
      "[90]\ttrain-rmse:0.236299\tvalid-rmse:0.246339\n",
      "[100]\ttrain-rmse:0.221303\tvalid-rmse:0.232359\n",
      "[110]\ttrain-rmse:0.21447\tvalid-rmse:0.226336\n",
      "[120]\ttrain-rmse:0.205326\tvalid-rmse:0.217802\n",
      "[130]\ttrain-rmse:0.203326\tvalid-rmse:0.21675\n",
      "[140]\ttrain-rmse:0.195485\tvalid-rmse:0.209856\n",
      "[150]\ttrain-rmse:0.194128\tvalid-rmse:0.209188\n",
      "[160]\ttrain-rmse:0.187765\tvalid-rmse:0.203539\n",
      "[170]\ttrain-rmse:0.178377\tvalid-rmse:0.19481\n",
      "[180]\ttrain-rmse:0.175451\tvalid-rmse:0.19234\n",
      "[190]\ttrain-rmse:0.170608\tvalid-rmse:0.187837\n",
      "[200]\ttrain-rmse:0.168245\tvalid-rmse:0.185726\n",
      "[210]\ttrain-rmse:0.161733\tvalid-rmse:0.179729\n",
      "[220]\ttrain-rmse:0.160597\tvalid-rmse:0.179161\n",
      "[226]\ttrain-rmse:0.158871\tvalid-rmse:0.177684\n",
      "Modeling RMSE 0.17768\n"
     ]
    }
   ],
   "source": [
    "model = utils.train_xgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 6: Add Aggregation Primitives</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_primitives = [Minute, Hour, Day, Week, Month, Weekday, Weekend]\n",
    "aggregation_primitives = [Sum, Mean, Median, Std]\n",
    "\n",
    "features = ft.dfs(entities=entities,\n",
    "                   relationships=relationships,\n",
    "                   target_entity=\"trips\",\n",
    "                   trans_primitives=trans_primitives,\n",
    "                   agg_primitives=aggregation_primitives,\n",
    "                   drop_contains=['trips.test_data'],\n",
    "                   features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Feature: payment_type>,\n",
       " <Feature: store_and_fwd_flag>,\n",
       " <Feature: dropoff_longitude>,\n",
       " <Feature: pickup_longitude>,\n",
       " <Feature: trip_duration>,\n",
       " <Feature: vendor_id>,\n",
       " <Feature: passenger_count>,\n",
       " <Feature: pickup_latitude>,\n",
       " <Feature: trip_distance>,\n",
       " <Feature: dropoff_latitude>,\n",
       " <Feature: MONTH(pickup_datetime)>,\n",
       " <Feature: HOUR(dropoff_datetime)>,\n",
       " <Feature: MINUTE(pickup_datetime)>,\n",
       " <Feature: HOUR(pickup_datetime)>,\n",
       " <Feature: WEEKDAY(dropoff_datetime)>,\n",
       " <Feature: DAY(pickup_datetime)>,\n",
       " <Feature: IS_WEEKEND(pickup_datetime)>,\n",
       " <Feature: IS_WEEKEND(dropoff_datetime)>,\n",
       " <Feature: WEEK(dropoff_datetime)>,\n",
       " <Feature: WEEK(pickup_datetime)>,\n",
       " <Feature: MONTH(dropoff_datetime)>,\n",
       " <Feature: WEEKDAY(pickup_datetime)>,\n",
       " <Feature: DAY(dropoff_datetime)>,\n",
       " <Feature: MINUTE(dropoff_datetime)>,\n",
       " <Feature: passenger_cnt.STD(trips.pickup_longitude)>,\n",
       " <Feature: passenger_cnt.SUM(trips.pickup_longitude)>,\n",
       " <Feature: vendors.SUM(trips.dropoff_longitude)>,\n",
       " <Feature: passenger_cnt.WEEKDAY(first_trips_time)>,\n",
       " <Feature: passenger_cnt.STD(trips.payment_type)>,\n",
       " <Feature: vendors.MEDIAN(trips.trip_distance)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.trip_distance)>,\n",
       " <Feature: vendors.HOUR(first_trips_time)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.dropoff_longitude)>,\n",
       " <Feature: vendors.WEEKDAY(first_trips_time)>,\n",
       " <Feature: passenger_cnt.DAY(first_trips_time)>,\n",
       " <Feature: vendors.SUM(trips.pickup_longitude)>,\n",
       " <Feature: vendors.STD(trips.trip_distance)>,\n",
       " <Feature: passenger_cnt.SUM(trips.pickup_latitude)>,\n",
       " <Feature: passenger_cnt.STD(trips.trip_duration)>,\n",
       " <Feature: passenger_cnt.MINUTE(first_trips_time)>,\n",
       " <Feature: passenger_cnt.HOUR(first_trips_time)>,\n",
       " <Feature: passenger_cnt.SUM(trips.trip_duration)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.dropoff_longitude)>,\n",
       " <Feature: vendors.STD(trips.pickup_latitude)>,\n",
       " <Feature: vendors.STD(trips.trip_duration)>,\n",
       " <Feature: vendors.MEAN(trips.payment_type)>,\n",
       " <Feature: vendors.MEAN(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.MONTH(first_trips_time)>,\n",
       " <Feature: vendors.SUM(trips.payment_type)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.payment_type)>,\n",
       " <Feature: vendors.MEDIAN(trips.dropoff_longitude)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.pickup_latitude)>,\n",
       " <Feature: passenger_cnt.MONTH(first_trips_time)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.dropoff_latitude)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.pickup_longitude)>,\n",
       " <Feature: vendors.WEEK(first_trips_time)>,\n",
       " <Feature: passenger_cnt.STD(trips.dropoff_longitude)>,\n",
       " <Feature: vendors.STD(trips.payment_type)>,\n",
       " <Feature: passenger_cnt.WEEK(first_trips_time)>,\n",
       " <Feature: vendors.SUM(trips.trip_distance)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.trip_distance)>,\n",
       " <Feature: vendors.MEDIAN(trips.trip_duration)>,\n",
       " <Feature: vendors.STD(trips.dropoff_longitude)>,\n",
       " <Feature: vendors.DAY(first_trips_time)>,\n",
       " <Feature: passenger_cnt.STD(trips.pickup_latitude)>,\n",
       " <Feature: vendors.SUM(trips.pickup_latitude)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.trip_duration)>,\n",
       " <Feature: passenger_cnt.SUM(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.MEDIAN(trips.pickup_latitude)>,\n",
       " <Feature: passenger_cnt.STD(trips.trip_distance)>,\n",
       " <Feature: vendors.SUM(trips.trip_duration)>,\n",
       " <Feature: passenger_cnt.SUM(trips.dropoff_longitude)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.pickup_latitude)>,\n",
       " <Feature: vendors.STD(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.SUM(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.MEAN(trips.pickup_latitude)>,\n",
       " <Feature: vendors.MINUTE(first_trips_time)>,\n",
       " <Feature: passenger_cnt.SUM(trips.payment_type)>,\n",
       " <Feature: vendors.MEAN(trips.trip_distance)>,\n",
       " <Feature: vendors.MEAN(trips.trip_duration)>,\n",
       " <Feature: vendors.STD(trips.pickup_longitude)>,\n",
       " <Feature: vendors.MEDIAN(trips.pickup_longitude)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.pickup_longitude)>,\n",
       " <Feature: vendors.MEDIAN(trips.dropoff_latitude)>,\n",
       " <Feature: passenger_cnt.SUM(trips.trip_distance)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.payment_type)>,\n",
       " <Feature: passenger_cnt.STD(trips.dropoff_latitude)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.trip_duration)>,\n",
       " <Feature: vendors.MEDIAN(trips.payment_type)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.MEAN(trips.pickup_longitude)>,\n",
       " <Feature: vendors.MEAN(trips.dropoff_longitude)>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix = compute_features(features,cutoff_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 6: Build the new model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separates the whole feature matrix into train data feature matrix, train data labels, and test data feature matrix \n",
    "X_train, y_train, X_test, y_test = utils.get_train_test_fm(feature_matrix,.75)\n",
    "y_train = np.log(y_train.values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3d5e2599dd3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/rkelly/DSx/utils.pyc\u001b[0m in \u001b[0;36mtrain_xgb\u001b[0;34m(X_train, labels)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     Xtr, Xv, ytr, yv = train_test_split(X_train.values,\n\u001b[0m\u001b[1;32m     35\u001b[0m                                         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                         \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mflot64\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3160\u001b[0m         \"\"\"\n\u001b[0;32m-> 3161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m   3140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m   3448\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3450\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3475\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3476\u001b[0m             \u001b[0mrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3477\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3478\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = utils.train_xgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 7: Evalute on test data  </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = utils.predict_xgb(model, X_test)\n",
    "y_pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred['trip_duration'])**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Additional Analysis</h2>\n",
    "<p>Let's look at how important each feature was for the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.values\n",
    "ft_importances = utils.feature_importances(model, feature_names)\n",
    "ft_importances[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
